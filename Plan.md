ğŸ—ºï¸ Master Plan: Weather DataOps Platform
Este documento detalla las fases de ejecuciÃ³n del proyecto, desde la base de infraestructura hasta la entrega de valor en dashboards.

ğŸ¯ Objetivo
Construir una plataforma de datos clonable y automatizada que extraiga informaciÃ³n de una API meteorolÃ³gica, la procese con estÃ¡ndares de ingenierÃ­a de software y la visualice, todo orquestado bajo principios DevOps.

ğŸ› ï¸ Fase 1: Cimientos e Infraestructura (En curso)
El objetivo es preparar el "escenario" donde correrÃ¡ nuestro cÃ³digo.

Estructura Monorepo: OrganizaciÃ³n de carpetas para separar responsabilidades (Infra, IngestiÃ³n, TransformaciÃ³n).

Git & CI inicial: ConfiguraciÃ³n de .gitignore y GitHub Actions para validar la calidad del cÃ³digo (Linting con Ruff y validaciÃ³n de Terraform).

Infraestructura como CÃ³digo (IaC): Uso de Terraform para levantar un clÃºster de Kubernetes (Kind) y una base de datos PostgreSQL local en Windows.

ğŸ Fase 2: IngestiÃ³n "Pythonic" y ContenerizaciÃ³n
AquÃ­ aplicamos ingenierÃ­a de software pura al flujo de datos.

Contratos de Datos: DefiniciÃ³n de modelos de datos con Pydantic V2 para asegurar la calidad desde el origen.

Cliente de API Robusto: Desarrollo de un cliente asÃ­ncrono (HTTPX) con manejo de errores, reintentos y logs profesionales.

DockerizaciÃ³n: CreaciÃ³n de Dockerfiles para empaquetar el ingestor como una unidad ejecutable e independiente.

Secrets Management: GestiÃ³n de API Keys mediante variables de entorno y secretos de GitHub.

ğŸ¼ Fase 3: OrquestaciÃ³n y Almacenamiento
El momento de unir las piezas y darles un orden lÃ³gico.

Despliegue en K8s: Desplegar nuestra base de datos y nuestro ingestor dentro del clÃºster local usando Terraform/Kubectl.

OrquestaciÃ³n con Dagster: Configurar Dagster como el "cerebro" que coordina cuÃ¡ndo se dispara la ingesta y verifica que los datos se han guardado correctamente.

Observabilidad: Implementar logs y alertas bÃ¡sicas para saber si la tuberÃ­a de datos falla.

ğŸ’ Fase 4: TransformaciÃ³n (La RefinerÃ­a)
Convertimos datos crudos en informaciÃ³n Ãºtil para negocio.

dbt (Data Build Tool): ImplementaciÃ³n de transformaciones SQL siguiendo el patrÃ³n Medallion Architecture:

Bronze: Datos crudos (Raw).

Silver: Datos limpios y tipados.

Gold: Tablas finales listas para anÃ¡lisis (ej. promedios mÃ³viles de temperatura).

Dual Stack: * Pruebas locales rÃ¡pidas con DuckDB.

SimulaciÃ³n de entorno corporativo con Databricks.

ğŸ“Š Fase 5: VisualizaciÃ³n y Data Governance
El cierre del cÃ­rculo: mostrar el valor y asegurar el control.

BI con Apache Superset: Despliegue de Superset en Kubernetes y creaciÃ³n de dashboards para visualizar el clima en tiempo real.

CatÃ¡logo de Datos: IntroducciÃ³n a DataHub para ver el linaje de los datos (de dÃ³nde vienen y quÃ© transformaciones han sufrido).

ğŸ“ˆ Resumen del Flujo de Datos Final
API OpenWeather â†’ Python Ingestor (K8s) â†’ Postgres (Bronze) â†’ dbt (Silver/Gold) â†’ Apache Superset